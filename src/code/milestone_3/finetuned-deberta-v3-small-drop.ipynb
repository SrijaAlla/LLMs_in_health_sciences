{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8255591,"sourceType":"datasetVersion","datasetId":4712304}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json","metadata":{"id":"qVNa22j50UAc","execution":{"iopub.status.busy":"2024-04-28T19:16:57.920925Z","iopub.execute_input":"2024-04-28T19:16:57.921215Z","iopub.status.idle":"2024-04-28T19:16:58.817286Z","shell.execute_reply.started":"2024-04-28T19:16:57.921189Z","shell.execute_reply":"2024-04-28T19:16:58.816499Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nfrom datasets import Dataset\nimport torch\nimport random\nimport math\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:16:58.819305Z","iopub.execute_input":"2024-04-28T19:16:58.819770Z","iopub.status.idle":"2024-04-28T19:17:16.410708Z","shell.execute_reply.started":"2024-04-28T19:16:58.819740Z","shell.execute_reply":"2024-04-28T19:17:16.409731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-28 19:17:07.900775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 19:17:07.900870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 19:17:08.037331: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# dataset = load_dataset(\"liuyanchen1015/MULTI_VALUE_mnli_drop_aux_be_gonna\")\n\ndataset = load_dataset(\"liuyanchen1015/MULTI_VALUE_mnli_drop_aux_have\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:16.416372Z","iopub.execute_input":"2024-04-28T19:17:16.417001Z","iopub.status.idle":"2024-04-28T19:17:24.735523Z","shell.execute_reply.started":"2024-04-28T19:17:16.416966Z","shell.execute_reply":"2024-04-28T19:17:24.734648Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3db004ead1b4111bdcb10845d510cf2"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 5.98M/5.98M [00:01<00:00, 5.79MB/s]\nDownloading data: 100%|██████████| 96.3k/96.3k [00:00<00:00, 168kB/s]\nDownloading data: 100%|██████████| 144k/144k [00:00<00:00, 252kB/s]\nDownloading data: 100%|██████████| 95.6k/95.6k [00:00<00:00, 168kB/s]\nDownloading data: 100%|██████████| 144k/144k [00:00<00:00, 246kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/39238 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"761847a6347a4e919ca8229b5420cf06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev_matched split:   0%|          | 0/983 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60955d9e4aa740b59fdd00d1a53d6058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev_mismatched split:   0%|          | 0/1230 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e141bffe5a2b43bb8663823b16e10eb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_matched split:   0%|          | 0/970 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"817d01429e6647f3bf7d0ead84142872"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_mismatched split:   0%|          | 0/1240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d65abcd5944db699dbb4fa4066c0b4"}},"metadata":{}}]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:24.736730Z","iopub.execute_input":"2024-04-28T19:17:24.737043Z","iopub.status.idle":"2024-04-28T19:17:24.742057Z","shell.execute_reply.started":"2024-04-28T19:17:24.737018Z","shell.execute_reply":"2024-04-28T19:17:24.741122Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'score'],\n        num_rows: 39238\n    })\n    dev_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'score'],\n        num_rows: 983\n    })\n    dev_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'score'],\n        num_rows: 1230\n    })\n    test_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'score'],\n        num_rows: 970\n    })\n    test_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx', 'score'],\n        num_rows: 1240\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(dataset,df):\n#     print(dataset[\"train\"])\n    for i in dataset[\"train\"]:\n#         print(i[\"hypothesis\"])\n        if(i[\"label\"] != 1):\n            new_row = pd.DataFrame([[i[\"hypothesis\"], i[\"premise\"], i[\"label\"]]], columns = ['hypothesis', 'premise','label'])\n            df = pd.concat([df, new_row], ignore_index=True)\n        \n    return df\n\ndef preprocess_val(dataset,df):\n#     print(dataset[\"\"])\n    for i in dataset[\"dev_matched\"]:\n#         print(i[\"hypothesis\"])\n        if(i[\"label\"] != 1):\n            new_row = pd.DataFrame([[i[\"hypothesis\"], i[\"premise\"], i[\"label\"]]], columns = ['hypothesis', 'premise','label'])\n            df = pd.concat([df, new_row], ignore_index=True)\n        \n    return df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"bSxG_jyC0UAd","outputId":"a2071c31-95cc-4353-95b0-b6b4a1c91676","execution":{"iopub.status.busy":"2024-04-28T19:17:24.743209Z","iopub.execute_input":"2024-04-28T19:17:24.743541Z","iopub.status.idle":"2024-04-28T19:17:24.790870Z","shell.execute_reply.started":"2024-04-28T19:17:24.743515Z","shell.execute_reply":"2024-04-28T19:17:24.789918Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame()\ndf_val = pd.DataFrame()\n# dataset[\"train\"][0][\"label\"]\ndf_train = preprocess(dataset,df_train)\ndf_val = preprocess_val(dataset, df_val)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:24.792234Z","iopub.execute_input":"2024-04-28T19:17:24.792584Z","iopub.status.idle":"2024-04-28T19:17:47.578687Z","shell.execute_reply.started":"2024-04-28T19:17:24.792554Z","shell.execute_reply":"2024-04-28T19:17:47.577799Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(df_train.columns)\ndf_train['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.579841Z","iopub.execute_input":"2024-04-28T19:17:47.580133Z","iopub.status.idle":"2024-04-28T19:17:47.598467Z","shell.execute_reply.started":"2024-04-28T19:17:47.580108Z","shell.execute_reply":"2024-04-28T19:17:47.597333Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Index(['hypothesis', 'premise', 'label'], dtype='object')\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([2, 0])"},"metadata":{}}]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.600011Z","iopub.execute_input":"2024-04-28T19:17:47.601023Z","iopub.status.idle":"2024-04-28T19:17:47.668400Z","shell.execute_reply.started":"2024-04-28T19:17:47.600988Z","shell.execute_reply":"2024-04-28T19:17:47.667487Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                          hypothesis  \\\n0         Neither Vrenna nor myself ever fought him.   \n1  The woman did not care where the man was as lo...   \n2  This is the only channel of expression of the ...   \n3  A recent law proposed by congress resulted in ...   \n4          The apartment's owner is very responsive.   \n5                  Mrs. Cavendish left the building.   \n6                        The man was perfectly fine.   \n7          True charity vaunts itself, we been told.   \n8  The town was only established in the past fift...   \n9                       The girl spoke very quietly.   \n\n                                             premise  label  \n0  Vrenna and I both fought him and he nearly too...      2  \n1  Felicia's Journey takes place behind the eyes ...      2  \n2  Thus, with respect to the litigation services ...      0  \n3  It might seemed like manna from heaven - up to...      2  \n4  Entreaties to the apartment's owner gone nowhere.      2  \n5     Mrs. Cavendish is in her mother-in-law's room.      2  \n6                     The man should died instantly.      2  \n7  We been told on reasonably high authority that...      2  \n8  This elegant spa town on the edge of the Lac d...      2  \n9  The word filled his head as though the girl wh...      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hypothesis</th>\n      <th>premise</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Neither Vrenna nor myself ever fought him.</td>\n      <td>Vrenna and I both fought him and he nearly too...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The woman did not care where the man was as lo...</td>\n      <td>Felicia's Journey takes place behind the eyes ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This is the only channel of expression of the ...</td>\n      <td>Thus, with respect to the litigation services ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A recent law proposed by congress resulted in ...</td>\n      <td>It might seemed like manna from heaven - up to...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The apartment's owner is very responsive.</td>\n      <td>Entreaties to the apartment's owner gone nowhere.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Mrs. Cavendish left the building.</td>\n      <td>Mrs. Cavendish is in her mother-in-law's room.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The man was perfectly fine.</td>\n      <td>The man should died instantly.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>True charity vaunts itself, we been told.</td>\n      <td>We been told on reasonably high authority that...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The town was only established in the past fift...</td>\n      <td>This elegant spa town on the edge of the Lac d...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The girl spoke very quietly.</td>\n      <td>The word filled his head as though the girl wh...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.672669Z","iopub.execute_input":"2024-04-28T19:17:47.673030Z","iopub.status.idle":"2024-04-28T19:17:47.678479Z","shell.execute_reply.started":"2024-04-28T19:17:47.673006Z","shell.execute_reply":"2024-04-28T19:17:47.677496Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"24629"},"metadata":{}}]},{"cell_type":"code","source":"len(df_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.679622Z","iopub.execute_input":"2024-04-28T19:17:47.679879Z","iopub.status.idle":"2024-04-28T19:17:47.688771Z","shell.execute_reply.started":"2024-04-28T19:17:47.679857Z","shell.execute_reply":"2024-04-28T19:17:47.687893Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"631"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    \n    # Standard metrics\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    prec = precision_score(labels, preds, average='binary', zero_division=0)  # Handling division by zero\n    recall = recall_score(labels, preds, average='binary', zero_division=0)   # Handling division by zero\n\n    faithfulness_metric = sum(preds != labels) / len(preds)\n    consistency_metric = sum(preds == labels) / len(preds) \n    \n    metrics = {\n        \"accuracy\": acc, \n        \"precision\": prec, \n        \"recall\": recall, \n        \"f1\": f1,\n        \"faithfulness\": faithfulness_metric,\n        \"consistency\": consistency_metric\n    }\n\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.689816Z","iopub.execute_input":"2024-04-28T19:17:47.690100Z","iopub.status.idle":"2024-04-28T19:17:47.699600Z","shell.execute_reply.started":"2024-04-28T19:17:47.690077Z","shell.execute_reply":"2024-04-28T19:17:47.698701Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:47.700588Z","iopub.execute_input":"2024-04-28T19:17:47.700835Z","iopub.status.idle":"2024-04-28T19:17:47.715217Z","shell.execute_reply.started":"2024-04-28T19:17:47.700813Z","shell.execute_reply":"2024-04-28T19:17:47.714326Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")\nmodel.to(device)  # Move model to CUDA if available\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGQRa7kL0UAh","outputId":"5f39b0e7-f06c-42da-c34b-1eafdd7d0fba","execution":{"iopub.status.busy":"2024-04-28T19:17:47.716361Z","iopub.execute_input":"2024-04-28T19:17:47.716680Z","iopub.status.idle":"2024-04-28T19:17:52.929591Z","shell.execute_reply.started":"2024-04-28T19:17:47.716649Z","shell.execute_reply":"2024-04-28T19:17:52.928678Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/500 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6229edcc84e0434f98ae4aac872d9ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7fc5ff2ac2454180a68fdee0a33808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f77342caa24529bc94caaa06ac6e1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc041826341d46d1a6b8488017baa78b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71a8125a6d74b56840b7c3fa9cd707d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/568M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ae1a5948ce47858d167db741b96331"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-5): 6 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): StableDropout()\n)"},"metadata":{}}]},{"cell_type":"code","source":"hypothesis_lst_train=df_train['hypothesis'].values.tolist()\nlen(hypothesis_lst_train)\n\n# print(hypothesis_lst_train)\n\nevidence_lst_train=df_train['premise'].values.tolist()\nlen(evidence_lst_train)\n\nlabel2id={2:0,0:1}\nlabel_lst_train=df_train['label'].apply(lambda x:label2id[x]).values.tolist()\nlen(label_lst_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:52.930937Z","iopub.execute_input":"2024-04-28T19:17:52.931315Z","iopub.status.idle":"2024-04-28T19:17:52.959558Z","shell.execute_reply.started":"2024-04-28T19:17:52.931282Z","shell.execute_reply":"2024-04-28T19:17:52.958703Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"24629"},"metadata":{}}]},{"cell_type":"code","source":"hypothesis_lst_val=df_val['hypothesis'].values.tolist()\nlen(hypothesis_lst_val)\n\nevidence_lst_val=df_val['premise'].values.tolist()\nlen(evidence_lst_val)\n\nlabel2id={2:0,0:1}\nlabel_lst_val=df_val['label'].apply(lambda x:label2id[x]).values.tolist()\nlen(label_lst_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:52.960568Z","iopub.execute_input":"2024-04-28T19:17:52.960866Z","iopub.status.idle":"2024-04-28T19:17:52.976151Z","shell.execute_reply.started":"2024-04-28T19:17:52.960842Z","shell.execute_reply":"2024-04-28T19:17:52.975307Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"631"},"metadata":{}}]},{"cell_type":"code","source":"class InputSequence:\n\n    def __init__(self,tok,l_text,l_text2,l_label,batch_size=64,gpu=True):\n\n        self.data_len=len(l_text)\n        self.data_idx=[i for i in range(self.data_len)]\n        self.texts=tok(l_text,l_text2,padding=True, truncation=True, max_length=512, return_tensors='pt')\n        self.l_label=np.array(l_label)\n        print('tokenize done')\n\n        self.batch_size=batch_size\n        self.gpu=gpu\n\n    def on_epoch_end(self):\n        random.shuffle(self.data_idx)\n\n    def __getitem__(self,i):\n        start=i*self.batch_size\n        batch_idx=self.data_idx[start:min(start+self.batch_size,self.data_len)]\n\n        return_texts=dict([(k,self.texts[k][batch_idx]) for k in self.texts])\n        return_labels=torch.from_numpy(\n            self.l_label[batch_idx].astype(np.int64)\n        )\n\n        if self.gpu:\n            return_texts=dict([(k,return_texts[k].cuda()) for k in return_texts])\n            return_labels=return_labels.cuda()\n\n        return return_texts,return_labels\n\n    def __len__(self):\n        return math.ceil(1.0*self.data_len/self.batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:52.977362Z","iopub.execute_input":"2024-04-28T19:17:52.977913Z","iopub.status.idle":"2024-04-28T19:17:52.988141Z","shell.execute_reply.started":"2024-04-28T19:17:52.977886Z","shell.execute_reply":"2024-04-28T19:17:52.987295Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"training_data=InputSequence(tokenizer,hypothesis_lst_train,evidence_lst_train,label_lst_train,gpu=True)\n# training_data.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:17:52.989295Z","iopub.execute_input":"2024-04-28T19:17:52.989698Z","iopub.status.idle":"2024-04-28T19:18:06.989927Z","shell.execute_reply.started":"2024-04-28T19:17:52.989667Z","shell.execute_reply":"2024-04-28T19:18:06.988900Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"tokenize done\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_data=InputSequence(tokenizer,hypothesis_lst_val,evidence_lst_val,label_lst_val,gpu=True)\n# testing_data.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:18:06.990812Z","iopub.execute_input":"2024-04-28T19:18:06.991071Z","iopub.status.idle":"2024-04-28T19:18:07.201105Z","shell.execute_reply.started":"2024-04-28T19:18:06.991048Z","shell.execute_reply":"2024-04-28T19:18:07.200092Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tokenize done\n","output_type":"stream"}]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,clf):\n        super(Model, self).__init__()\n        self.clf=clf\n        self.loss=nn.CrossEntropyLoss()\n\n    def forward(self, texts, labels, gpu=True):\n\n        loss=self.loss(self.clf(**texts).logits, labels)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:18:07.202533Z","iopub.execute_input":"2024-04-28T19:18:07.202842Z","iopub.status.idle":"2024-04-28T19:18:07.208329Z","shell.execute_reply.started":"2024-04-28T19:18:07.202815Z","shell.execute_reply":"2024-04-28T19:18:07.207418Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model=Model(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:18:07.209401Z","iopub.execute_input":"2024-04-28T19:18:07.209677Z","iopub.status.idle":"2024-04-28T19:18:07.220479Z","shell.execute_reply.started":"2024-04-28T19:18:07.209654Z","shell.execute_reply":"2024-04-28T19:18:07.219590Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport torch\nfrom torch import nn\nfrom transformers import AdamW\nimport numpy as np\nimport math\nimport random\n\nbat_s = 16\nl_rate = 1e-5\n\ntraining_data.batch_size = bat_s\n\nmodel.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=l_rate)\ntotal_epoch_num = 10\n\nfor epoch in range(total_epoch_num):\n    training_data.on_epoch_end()\n    loss_sum = 0.0\n    loss_count = 0\n    model.train()  # Ensure model is in training mode\n    \n    for batch in range(len(training_data)):\n        optimizer.zero_grad()\n        batch_texts, batch_labels = training_data[batch]\n        loss_count += len(batch_texts['input_ids'])\n        loss = model(batch_texts, batch_labels)\n        print('epoch:', epoch, 'batch:', batch, 'loss:', loss.item(), end='\\n' if batch == 0 or batch + 1 == len(training_data) or (batch + 1) % 1000 == 0 else '\\r')\n        loss_sum += loss.item() * len(batch_texts['input_ids'])\n        loss.backward()\n        optimizer.step()\n        \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss_sum = 0.0\n    val_loss_count = 0\n    with torch.no_grad():\n        for batch in range(len(testing_data)):\n            batch_texts, batch_labels = testing_data[batch]\n            val_loss_count += len(batch_texts['input_ids'])\n            val_loss = model(batch_texts, batch_labels)\n            val_loss_sum += val_loss.item() * len(batch_texts['input_ids'])\n\n    avg_val_loss = val_loss_sum / val_loss_count\n    print(f'Validation - Epoch: {epoch}, Avg Loss: {avg_val_loss}')\n\n    # Save the model after each epoch\n    model_path = f'./clf_models/debertav3small-NLI4CT_epoch_{epoch:05d}.pt'\n    model.clf.save_pretrained(model_path)\n    print(f'Model saved to {model_path}')\n\n_ = model.cpu()  # Move model back to CPU if necessary","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:18:07.221577Z","iopub.execute_input":"2024-04-28T19:18:07.221813Z","iopub.status.idle":"2024-04-28T21:28:04.580844Z","shell.execute_reply.started":"2024-04-28T19:18:07.221792Z","shell.execute_reply":"2024-04-28T21:28:04.579970Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"epoch: 0 batch: 0 loss: 3.8002829551696777\nepoch: 0 batch: 999 loss: 0.030682923272252083\nepoch: 0 batch: 1539 loss: 0.880515277385711785\nValidation - Epoch: 0, Avg Loss: 0.16331484800473256\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00000.pt\nepoch: 1 batch: 0 loss: 0.04611135646700859\nepoch: 1 batch: 1539 loss: 0.4273086488246918786\nValidation - Epoch: 1, Avg Loss: 0.16594882167745884\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00001.pt\nepoch: 2 batch: 0 loss: 0.030298316851258278\nepoch: 2 batch: 999 loss: 0.0029025170952081687\nepoch: 2 batch: 1539 loss: 0.3387764096260071675\nValidation - Epoch: 2, Avg Loss: 0.1969204293283532\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00002.pt\nepoch: 3 batch: 0 loss: 0.007501743733882904\nepoch: 3 batch: 999 loss: 0.01502662897109985454\nepoch: 3 batch: 1539 loss: 0.00012554053682833917\nValidation - Epoch: 3, Avg Loss: 0.275814410151468\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00003.pt\nepoch: 4 batch: 0 loss: 0.0003194752207491547\nepoch: 4 batch: 999 loss: 0.00539624691009521534\nepoch: 4 batch: 1539 loss: 0.03576842695474624656\nValidation - Epoch: 4, Avg Loss: 0.24102006231548292\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00004.pt\nepoch: 5 batch: 0 loss: 0.04978103190660477\nepoch: 5 batch: 999 loss: 0.00710328761488199233\nepoch: 5 batch: 1539 loss: 0.00923681445419788464\nValidation - Epoch: 5, Avg Loss: 0.24838162311566803\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00005.pt\nepoch: 6 batch: 0 loss: 0.013165068812668324\nepoch: 6 batch: 999 loss: 0.00440924335271120166\nepoch: 6 batch: 1539 loss: 0.00014747037494089454\nValidation - Epoch: 6, Avg Loss: 0.2434034652878101\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00006.pt\nepoch: 7 batch: 0 loss: 0.014471156522631645\nepoch: 7 batch: 999 loss: 0.00491419341415166854\nepoch: 7 batch: 1539 loss: 0.00010606200521579012\nValidation - Epoch: 7, Avg Loss: 0.2939269001434798\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00007.pt\nepoch: 8 batch: 0 loss: 6.428625783883035e-05\nepoch: 8 batch: 999 loss: 0.00097061041742563254\nepoch: 8 batch: 1539 loss: 0.9728446006774902e-05\nValidation - Epoch: 8, Avg Loss: 0.33755325095022537\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00008.pt\nepoch: 9 batch: 0 loss: 0.00045210387906990945\nepoch: 9 batch: 999 loss: 0.01217360235750675248\nepoch: 9 batch: 1539 loss: 0.00011460254609119147\nValidation - Epoch: 9, Avg Loss: 0.2980670281427598\nModel saved to ./clf_models/debertav3small-NLI4CT_epoch_00009.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}